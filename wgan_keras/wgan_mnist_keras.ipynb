{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WGAN对GAN的改进:\n",
    "\n",
    "- 判别器最后一层去掉sigmoid\n",
    "\n",
    "- 生成器和判别器的loss不取log\n",
    "\n",
    "- 更新后的权重强制截断到一定范围内，比如[-0.01，0.01]，以满足论文中提到的lipschitz连续性条件。\n",
    "\n",
    "- 论文中推荐使用SGD， RMSprop等优化器，不要基于使用动量的优化算法(包括momentum和Adam)。\n",
    "\n",
    "\n",
    "\n",
    "WGAN的作用：\n",
    "\n",
    "- WGAN理论上给出了GAN训练不稳定的原因，即交叉熵（JS散度）不适合衡量具有不相交部分的分布之间的距离，转而使用wassertein距离去衡量生成数据分布和真实数据分布之间的距离，理论上解决了训练不稳定的问题。\n",
    "- 解决了模式崩溃的（collapse mode）问题，生成结果多样性更丰富。\n",
    "- 对GAN的训练提供了一个指标，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator(input_shape, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Conv2D(channels, kernel_size=4, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.summary()\n",
    "    \n",
    "    input_noise = Input(shape=input_shape)\n",
    "    gen_v = model(input_noise)\n",
    "    model_generator = Model(input_noise, gen_v)\n",
    "    \n",
    "    return model_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "\n",
    "    input_img = Input(shape=img_shape)\n",
    "    validity = model(input_img)\n",
    "    model_discriminator = Model(input_img, validity)\n",
    "    return model_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 98,561\n",
      "Trainable params: 98,113\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 971,841\n",
      "Trainable params: 971,201\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "shape = (100,)\n",
    "\n",
    "# Following parameter and optimizer set as recommended in paper\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "# Build and compile the critic\n",
    "critic = build_discriminator(img_shape)\n",
    "critic.compile(loss=wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(shape, channels)\n",
    "\n",
    "# The generator takes noise as input and generated imgs\n",
    "z = Input(shape=shape)\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "critic.trainable = False\n",
    "\n",
    "# The critic takes generated images as input and determines validity\n",
    "valid = critic(img)\n",
    "\n",
    "# The combined model  (stacked generator and critic)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss=wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 1\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(12,8))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "            \n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "        \n",
    "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, model, epochs=100, batch_size=64, save_interval=50):\n",
    "    (generator, critic, combined) = model\n",
    "    \n",
    "    # Adversarial ground truths\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    fake = np.ones((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for step in range(n_critic):\n",
    "            #  Train Discriminator\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100)) #latent_dim=100\n",
    "            \n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            \n",
    "            # Train the critic\n",
    "            d_loss_real = critic.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = critic.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "                \n",
    "            # Clip critic weights\n",
    "            for l in critic.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "                \n",
    "        #  Train Generator\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "            \n",
    "        if (epoch % save_interval == 0) or (epoch == 1):\n",
    "            save_imgs(epoch)\n",
    "            print(\"Epoch: %d, Discriminator Loss: %f, Generator loss: %f\" % (epoch, 1-d_loss[0], 1-g_loss[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# X_train = np.concatenate((X_train, X_test), axis=0)\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = (generator, critic, combined)\n",
    "\n",
    "train(X_train, model, epochs=8000, batch_size=32, save_interval=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
